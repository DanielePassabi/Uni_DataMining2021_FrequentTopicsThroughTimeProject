{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"02_2_APriori_definitive_function.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"-I-RLIw1wJeE"},"source":["# APriori algorithm\n","We have a clean dataset, we can now find frequent itemset in the data.\n","\n","The first algorithm that I'll use is APriori."]},{"cell_type":"markdown","metadata":{"id":"LWaxFYpbwJeJ"},"source":["## Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"femDo-zywJeJ","executionInfo":{"status":"ok","timestamp":1609853648580,"user_tz":-60,"elapsed":984,"user":{"displayName":"Daniele Passabì","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTdCzebRMUcq7sYI0VdgqMCmvU71oBkYZkuNxPkQ=s64","userId":"03034249883816696713"}},"outputId":"f21d1d6a-dfa3-4ab0-b978-fed3bb81a1df"},"source":["import pandas as pd\n","import math\n","import plotly.express as px     # used to plot the data\n","import ast                      # used to transform string into list\n","from collections import Counter # used to count the occurrences of hashtags\n","from statistics import mean\n","import string                   # used to remove punctuation from text in an efficient way\n","from tqdm import tqdm\n","import datetime\n","from efficient_apriori import apriori\n","import json\n","import time\n","\n","print(\"All libreries imported\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["All libreries imported\n"]}]},{"cell_type":"markdown","metadata":{"id":"wVF12Qd4wJeK"},"source":["## Import the clean dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"Yg-bmw1RwJeK","executionInfo":{"status":"error","timestamp":1609853651922,"user_tz":-60,"elapsed":1515,"user":{"displayName":"Daniele Passabì","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTdCzebRMUcq7sYI0VdgqMCmvU71oBkYZkuNxPkQ=s64","userId":"03034249883816696713"}},"outputId":"cd2fbc54-8eaa-4c20-9ff2-0ea6974adc62"},"source":["df_path = \"../data/clean_df/clean_df.pkl\"\n","df = pd.read_pickle(df_path)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AgWLHkVdwJeL"},"source":["## APriori on all days\n","\n","### \\#1 Compute APriori algorithm for each day of the dataset"]},{"cell_type":"code","metadata":{"id":"WcxUEWw-wJeL","outputId":"a819e212-fdd1-483f-9489-b56b120fff15"},"source":["start = time.time()\n","\n","curr_day = datetime.date(2020, 7, 24)  # first day of the data\n","last_day = datetime.date(2020, 8, 30)  # last day of the data\n","results_list = []\n","\n","# iterate on every day of the dataset (until we reach the last one)\n","while (curr_day <= last_day):\n","\n","    # prepare the list of item of the day\n","    texts_for_apriori = []\n","    for t in df.loc[df['date'] == curr_day][\"text\"]:\n","        texts_for_apriori.append(t)\n","\n","    print(\" >> Computing APriori on day: \", curr_day, \" | Total tweets: \", len(texts_for_apriori))\n","\n","\n","    # computation of APriori [only if Total tweets > 0]\n","    if len(texts_for_apriori) > 0:\n","        itemsets, rules = apriori(texts_for_apriori, min_support=0.012,  min_confidence=0.8)\n","\n","        # Save the results in a more convenient way\n","        list_of_groups = []\n","        for item in itemsets.values():\n","            list_of_groups.append(item)   # there are always groups of 1, 2 and 3 words. Sometimes more.\n","\n","        threshold = 0.015\n","        daily_groups = []\n","        for group in list_of_groups:\n","            daily_groups.append({k: v/len(texts_for_apriori) for k, v in group.items() if v/len(texts_for_apriori) > threshold})\n","        \n","        results_list.append([curr_day, daily_groups])\n","\n","    else:\n","        # Save the day and an empty list\n","        results_list.append([curr_day, [{}]])\n","\n","    # add 1 day and repeat the procedure\n","    curr_day = curr_day + datetime.timedelta(days=1)\n","\n","end = time.time()\n","print(\" > Elapsed time: \", end - start)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[" >> Computing APriori on day:  2020-07-24  | Total tweets:  295\n"," >> Computing APriori on day:  2020-07-25  | Total tweets:  16881\n"," >> Computing APriori on day:  2020-07-26  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-07-27  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-07-28  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-07-29  | Total tweets:  2780\n"," >> Computing APriori on day:  2020-07-30  | Total tweets:  1980\n"," >> Computing APriori on day:  2020-07-31  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-01  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-02  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-03  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-04  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-05  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-06  | Total tweets:  7214\n"," >> Computing APriori on day:  2020-08-07  | Total tweets:  1060\n"," >> Computing APriori on day:  2020-08-08  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-09  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-10  | Total tweets:  4891\n"," >> Computing APriori on day:  2020-08-11  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-12  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-13  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-14  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-15  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-16  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-17  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-18  | Total tweets:  7500\n"," >> Computing APriori on day:  2020-08-19  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-20  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-21  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-22  | Total tweets:  11555\n"," >> Computing APriori on day:  2020-08-23  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-24  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-25  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-26  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-27  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-28  | Total tweets:  0\n"," >> Computing APriori on day:  2020-08-29  | Total tweets:  4077\n"," >> Computing APriori on day:  2020-08-30  | Total tweets:  8375\n"," > Elapsed time:  64.77929043769836\n"]}]},{"cell_type":"markdown","metadata":{"id":"TaSvVLNYwJeL"},"source":["### Viewing the results\n","A simple example"]},{"cell_type":"code","metadata":{"id":"OEQY_61DwJeL"},"source":["#results_list[2]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EPE-qW54wJeM"},"source":["### \\#2 Check if the groups appear in different dates\n","#### Check 1: groups of two words\n","#### Check 2: groups of three words"]},{"cell_type":"code","metadata":{"tags":[],"id":"82VSSp3GwJeM","outputId":"cf63727f-71a6-4b3f-bc83-fb857b0a70ba"},"source":["DEBUG = False\n","\n","final_results = {}\n","\n","# iterate on every [date, [[group_of_2],[group_of_3]]]\n","for res in tqdm(results_list):\n","\n","    date = res[0]           # get the date\n","    list_of_groups = res[1] # in pos 0 --> 1 word, in pos 1 --> 2 words, ...\n","\n","    # iterate on every pair of every groups\n","\n","    for group in list_of_groups:\n","\n","        for key, value in group.items():\n","\n","            if DEBUG:\n","                print(date)\n","                print(key)\n","\n","            # if the key is already in the solutions dict --> update its value with current data \n","            if key in final_results:\n","                final_results[key][0].append(date)\n","                final_results[key][1].append(value)\n","\n","            # if it is a new group --> create a list with the date value\n","            else:\n","                final_results[key] = [[date],[value]]\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 38/38 [00:00<00:00, 19051.34it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"6lrHrVEOwJeM"},"source":["## Save the data in a dataframe \n","and as .csv and .pkl"]},{"cell_type":"code","metadata":{"id":"6k9kDWnvwJeM","outputId":"8342a32a-880d-4955-ad51-44d53e53fbeb"},"source":["words_column = []\n","dates_column = []\n","count_column = []\n","for k,v in final_results.items():\n","    words_column.append(k)\n","    dates_column.append(v[0])\n","    count_column.append(v[1])\n","\n","final_results_df = pd.DataFrame(\n","    {'group_of_words': words_column,\n","     'dates': dates_column,\n","     'frequencies': count_column\n","    })\n","\n","final_results_df"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 group_of_words  \\\n","0                      (covid,)   \n","1                       (good,)   \n","2                       (live,)   \n","3                 (coronaviru,)   \n","4                     (pandem,)   \n","...                         ...   \n","1470               (hour, last)   \n","1471        (covid, india, new)   \n","1472         (case, india, new)   \n","1473  (case, covid, death, new)   \n","1474  (case, covid, india, new)   \n","\n","                                                  dates  \\\n","0     [2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...   \n","1     [2020-07-24, 2020-07-25, 2020-07-28, 2020-08-0...   \n","2     [2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...   \n","3     [2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...   \n","4     [2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...   \n","...                                                 ...   \n","1470                                       [2020-08-30]   \n","1471                                       [2020-08-30]   \n","1472                                       [2020-08-30]   \n","1473                                       [2020-08-30]   \n","1474                                       [2020-08-30]   \n","\n","                                            frequencies  \n","0     [0.5728813559322034, 0.6070730406966411, 0.618...  \n","1     [0.020338983050847456, 0.015283454771636751, 0...  \n","2     [0.02711864406779661, 0.019489366743676323, 0....  \n","3     [0.0847457627118644, 0.08601386173804869, 0.1,...  \n","4     [0.06440677966101695, 0.0444286475919673, 0.04...  \n","...                                                 ...  \n","1470                              [0.01528358208955224]  \n","1471                             [0.016955223880597014]  \n","1472                             [0.017194029850746268]  \n","1473                             [0.020417910447761194]  \n","1474                             [0.015880597014925373]  \n","\n","[1475 rows x 3 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group_of_words</th>\n      <th>dates</th>\n      <th>frequencies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(covid,)</td>\n      <td>[2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...</td>\n      <td>[0.5728813559322034, 0.6070730406966411, 0.618...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(good,)</td>\n      <td>[2020-07-24, 2020-07-25, 2020-07-28, 2020-08-0...</td>\n      <td>[0.020338983050847456, 0.015283454771636751, 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(live,)</td>\n      <td>[2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...</td>\n      <td>[0.02711864406779661, 0.019489366743676323, 0....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(coronaviru,)</td>\n      <td>[2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...</td>\n      <td>[0.0847457627118644, 0.08601386173804869, 0.1,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(pandem,)</td>\n      <td>[2020-07-24, 2020-07-25, 2020-07-26, 2020-07-2...</td>\n      <td>[0.06440677966101695, 0.0444286475919673, 0.04...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1470</th>\n      <td>(hour, last)</td>\n      <td>[2020-08-30]</td>\n      <td>[0.01528358208955224]</td>\n    </tr>\n    <tr>\n      <th>1471</th>\n      <td>(covid, india, new)</td>\n      <td>[2020-08-30]</td>\n      <td>[0.016955223880597014]</td>\n    </tr>\n    <tr>\n      <th>1472</th>\n      <td>(case, india, new)</td>\n      <td>[2020-08-30]</td>\n      <td>[0.017194029850746268]</td>\n    </tr>\n    <tr>\n      <th>1473</th>\n      <td>(case, covid, death, new)</td>\n      <td>[2020-08-30]</td>\n      <td>[0.020417910447761194]</td>\n    </tr>\n    <tr>\n      <th>1474</th>\n      <td>(case, covid, india, new)</td>\n      <td>[2020-08-30]</td>\n      <td>[0.015880597014925373]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1475 rows × 3 columns</p>\n</div>"},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"NXSAGfnKwJeN"},"source":["# save the data (could be useful in the future)\n","final_results_df.to_csv(\"../data/results/apriori_df.csv\")\n","final_results_df.to_pickle(\"../data/results/apriori_df.pkl\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"4byRpdBqwJeN"},"source":[],"execution_count":null,"outputs":[]}]}